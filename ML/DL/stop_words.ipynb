{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5207c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\abhin\\onedrive\\documents\\code\\ml\\udemy\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\abhin\\onedrive\\documents\\code\\ml\\udemy\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\abhin\\onedrive\\documents\\code\\ml\\udemy\\venv\\lib\\site-packages (from nltk) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\abhin\\onedrive\\documents\\code\\ml\\udemy\\venv\\lib\\site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhin\\onedrive\\documents\\code\\ml\\udemy\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhin\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab06692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3600eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\abhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e171436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')\n",
    "# stopwords.words('german')\n",
    "# stopwords.words('french')\n",
    "# stopwords.words('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "654e7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Natural Language Processing is a fascinating field of artificial intelligence. \n",
    "It helps computers understand and process human language. NLP has many applications including \n",
    "sentiment analysis, machine translation, and chatbots. The quick brown fox jumps over the lazy dog.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29ce3e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural Language Processing is a fascinating field of artificial intelligence.', 'It helps computers understand and process human language.', 'NLP has many applications including \\nsentiment analysis, machine translation, and chatbots.', 'The quick brown fox jumps over the lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentences_2 = sent_tokenize(paragraph)\n",
    "print(sentences_2)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(sentences_2)):\n",
    "    words = word_tokenize(sentences_2[i])\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in english_stopwords]\n",
    "    sentences_2[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc7bd78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural language processing fascinating field artificial intelligence .', 'help computer understand process human language .', 'nlp many application including sentiment analysis , machine translation , chatbots .', 'quick brown fox jump lazy dog .']\n"
     ]
    }
   ],
   "source": [
    "print(sentences_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09d50f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural Language Processing is a fascinating field of artificial intelligence.', 'It helps computers understand and process human language.', 'NLP has many applications including \\nsentiment analysis, machine translation, and chatbots.', 'The quick brown fox jumps over the lazy dog.']\n",
      "['Natural', 'Language', 'Processing', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', '.']\n",
      "['It', 'helps', 'computers', 'understand', 'and', 'process', 'human', 'language', '.']\n",
      "['NLP', 'has', 'many', 'applications', 'including', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'and', 'chatbots', '.']\n",
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentences = sent_tokenize(paragraph)\n",
    "print(sentences)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    print(words)\n",
    "    words = [stemmer.stem(word) for word in words if word.lower() not in english_stopwords]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c01235",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    \n",
    "    sentences[i] = sentences[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "814c1bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur languag process fascin field artifici intellig .', 'help comput understand process human languag .', 'nlp mani applic includ sentiment analysi , machin translat , chatbot .', 'quick brown fox jump lazi dog .']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "848a4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word.lower() not in english_stopwords]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d98dc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur languag process fascin field artifici intellig .', 'help comput understand process human languag .', 'nlp mani applic includ sentiment analysi , machin translat , chatbot .', 'quick brown fox jump lazi dog .']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf95e5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur languag process fascin field artifici intellig .', 'help comput understand process human languag .', 'nlp mani applic includ sentiment analysi , machin translat , chatbot .', 'quick brown fox jump lazi dog .']\n",
      "['natur', 'languag', 'process', 'fascin', 'field', 'artifici', 'intellig', '.']\n",
      "['natur', 'languag', 'process', 'fascin', 'field', 'artifici', 'intellig', '.']\n",
      "['natur languag process fascin field artifici intellig .', 'help comput understand process human languag .', 'nlp mani applic includ sentiment analysi , machin translat , chatbot .', 'quick brown fox jump lazi dog .']\n",
      "['help', 'comput', 'understand', 'process', 'human', 'languag', '.']\n",
      "['help', 'comput', 'understand', 'process', 'human', 'languag', '.']\n",
      "['natur languag process fascin field artifici intellig .', 'help comput understand process human languag .', 'nlp mani applic includ sentiment analysi , machin translat , chatbot .', 'quick brown fox jump lazi dog .']\n",
      "['nlp', 'mani', 'applic', 'includ', 'sentiment', 'analysi', ',', 'machin', 'translat', ',', 'chatbot', '.']\n",
      "['nlp', 'mani', 'applic', 'includ', 'sentiment', 'analysi', ',', 'machin', 'translat', ',', 'chatbot', '.']\n",
      "['natur languag process fascin field artifici intellig .', 'help comput understand process human languag .', 'nlp mani applic includ sentiment analysi , machin translat , chatbot .', 'quick brown fox jump lazi dog .']\n",
      "['quick', 'brown', 'fox', 'jump', 'lazi', 'dog', '.']\n",
      "['quick', 'brown', 'fox', 'jump', 'lazi', 'dog', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print(sentences)\n",
    "    words = word_tokenize(sentences[i])\n",
    "    print(words)\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in english_stopwords]\n",
    "    print(words)\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7e5ad1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur languag process fascin field artifici intellig .',\n",
       " 'help comput understand process human languag .',\n",
       " 'nlp mani applic includ sentiment analysi , machin translat , chatbot .',\n",
       " 'quick brown fox jump lazi dog .']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d0062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
